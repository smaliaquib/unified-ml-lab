{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e54b813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List\n",
    "from datasets import Dataset, load_dataset\n",
    "from openai import OpenAI\n",
    "from tqdm.auto import tqdm\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a23214df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answer(\n",
    "    instruction: str, answer: str, client: OpenAI\n",
    " ) -> dict:\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert judge. Please evaluate the quality of a given answer to an instruction based on two criteria:\n",
    "        \n",
    "            1. Accuracy: How factually correct is the information presented in \n",
    "            the answer? You are a technical expert in this topic.\n",
    "\n",
    "            2. Style: Is the tone and writing style appropriate for a blog post \n",
    "            or social media content? It should use simple but technical words \n",
    "            and avoid formal or academic language.\n",
    "\n",
    "        Accuracy scale:\n",
    "            1 (Poor): Contains factual errors or misleading information\n",
    "            2 (Good): Mostly accurate with minor errors or omissions\n",
    "            3 (Excellent): Highly accurate and comprehensive\n",
    "\n",
    "        Style scale:\n",
    "            1 (Poor): Too formal, uses some overly complex words\n",
    "            2 (Good): Good balance of technical content and accessibility, but \n",
    "            still uses formal words and expressions\n",
    "            3 (Excellent): Perfectly accessible language for blog/social media, \n",
    "            uses simple but precise technical terms when necessary\n",
    "        \n",
    "    Example of bad style: The Llama2 7B model constitutes a noteworthy progression in the field of artificial intelligence, serving as the successor to its predecessor, the original Llama architecture.\n",
    "    Example of excellent style: Llama2 7B outperforms the original Llama model across multiple benchmarks.\n",
    "    Instruction: {instruction}\n",
    "    Answer: {answer}\n",
    "    Provide your evaluation in JSON format with the following structure:\n",
    "    {{\n",
    "        \"accuracy\": {{\n",
    "        \"analysis\": \"...\",\n",
    "        \"score\": 0\n",
    "        }},\n",
    "        \"style\": {{\n",
    "        \"analysis\": \"...\",\n",
    "        \"score\": 0\n",
    "        }}\n",
    "    }}\n",
    "    \"\"\"\n",
    "\n",
    "    completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant who evaluates answers based on accuracy and style. Provide your response in JSON format with a short analysis and score for each criterion.\",\n",
    "            },\n",
    "                \n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        max_tokens=1000,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "\n",
    "    return json.loads(completion.choices[0].message.content)\n",
    "\n",
    "def evaluate_batch(batch, start_index):\n",
    "    client = OpenAI()\n",
    "    return [\n",
    "        (i, evaluate_answer(instr, ans, client))\n",
    "        for i, (instr, ans) in enumerate(batch, start=start_index)\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc486760",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_answers(model_id: str, num_threads: int = 10, batch_size: int = 5) -> Dataset:\n",
    "    dataset = load_dataset(f\"SkillRipper/{model_id.split('/')[-1]}-results\", split=\"all\")\n",
    "    batches = [(i, list(zip(dataset[\"instruction\"][i:i+batch_size], dataset[\"answers\"][i:i+batch_size]))) for i in range(0, len(dataset), batch_size)]\n",
    "\n",
    "    evaluations = [None] * len(dataset)\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=num_threads) as executor:\n",
    "        futures = [executor.submit(evaluate_batch, batch, start_index) for start_index, batch in batches]\n",
    "        for future in tqdm(concurrent.futures.as_completed(futures), total=len(futures)):\n",
    "            for index, evaluation in future.result():\n",
    "                evaluations[index] = evaluation\n",
    "\n",
    "    if 'evaluation' in dataset.column_names:\n",
    "        dataset = dataset.remove_columns(['evaluation'])\n",
    "    dataset = dataset.add_column(\"evaluation\", evaluations)\n",
    "\n",
    "    accuracy_scores = []\n",
    "    style_scores = []\n",
    "\n",
    "    for evaluation in dataset['evaluation']:\n",
    "        # print(evaluation)\n",
    "        try:\n",
    "            eval_dict = json.loads(evaluation) if isinstance(evaluation, str) else evaluation\n",
    "            accuracy_score = eval_dict['accuracy']['score']\n",
    "            style_score = eval_dict['style']['score']\n",
    "            accuracy_scores.append(accuracy_score)\n",
    "            style_scores.append(style_score)\n",
    "        except (json.JSONDecodeError, KeyError, TypeError):\n",
    "            accuracy_scores.append(None)\n",
    "            style_scores.append(None)\n",
    "        \n",
    "    if 'accuracy' in dataset.column_names:\n",
    "        dataset = dataset.remove_columns(['accuracy'])\n",
    "    dataset = dataset.add_column('accuracy', accuracy_scores)\n",
    "    if 'style' in dataset.column_names:\n",
    "        dataset = dataset.remove_columns(['style'])\n",
    "    dataset = dataset.add_column('style', style_scores)\n",
    "\n",
    "    # Compute and print model-wide average\n",
    "    avg_accuracy = sum(score for score in accuracy_scores if score is not None) / len([s for s in accuracy_scores if s is not None])\n",
    "    avg_style = sum(score for score in style_scores if score is not None) / len([s for s in style_scores if s is not None])\n",
    "\n",
    "    print(f\"{model_id.split('/')[-1]} - Accuracy: {avg_accuracy:.2f}\")\n",
    "    print(f\"{model_id.split('/')[-1]} - Style: {avg_style:.2f}\")\n",
    "\n",
    "    dataset.push_to_hub(f\"SkillRipper/{model_id.split('/')[-1]}-results\")\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64d7165c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ids = ['unsloth/Llama-3.2-3B-Instruct', 'SkillRipper/TwinLlama-3.2-3B-DPO', 'SkillRipper/TwinLlama-3.2-3B-Instruct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572605df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "319e4e8ea31b44eb8d4ca2a6b3f1814d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bfc0a94cc2d49588916adc139447740",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/300k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f882449c0140ff96786f534cc9b5f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc9c8d066bd444d7b26eb0ad44367708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Llama-3.2-3B-Instruct - Accuracy: 2.70\n",
      "Llama-3.2-3B-Instruct - Style: 1.98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e464f61423744e1bfa033d88ab918ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3bad1040aa41b2be7ba6a84ac5fef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34df6243debd4b70a83fa7c06b728ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d284f33a901c46c0a9f5708fbc54efb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/208k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5124b5292aa4ce183974f50a95a8909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a29d38b2c24a0cbc4b6c30cf3c0088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwinLlama-3.2-3B-DPO - Accuracy: 2.38\n",
      "TwinLlama-3.2-3B-DPO - Style: 2.02\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa0580428984b2b87c39b31dde794a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce7be1afabf442dbe387e73b0808ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db8deec22fa412d9720c6d156ad1218",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30b642c143724ca985b0b4bd9a5f9815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/209k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5719db51cbfc4f3289378fd94b79d4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/211 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d274ea3bf31842088d98bd53cba7a1ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/43 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TwinLlama-3.2-3B-Instruct - Accuracy: 2.41\n",
      "TwinLlama-3.2-3B-Instruct - Style: 2.01\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "074b1665ae5e41798099227c75a318c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15b52263db754d48b14ac31469599ecd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for model_id in model_ids:\n",
    "    evaluate_answers(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b62327c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mirrormuse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
